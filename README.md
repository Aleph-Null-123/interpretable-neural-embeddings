# Interpretable Latent Representations of Neural Activity via Sparse Autoencoders
Project repository for: Interpretable Latent Representations of Neural Activity via Sparse Autoencoders

This project explores how sparse autoencoders can improve the interpretability of neural embeddings generated by CEBRA, a contrastive learning method for generating embeddings for neural data. By enforcing sparsity in the embeddings we show that representations align more with behavioral and neuronal structure, while preserving decoding performance.

Detailed written report available in PDF format in this repo.
